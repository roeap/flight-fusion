# Default values for mlflow.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# -- (int) Numbers of replicas
replicaCount: 1

# Image of mlflow
image:
  # -- The docker image repository to use
  repository: mlflow
  # -- The docker image pull policy
  pullPolicy: IfNotPresent
  # -- The docker image tag to use. Default app version
  tag: ""

# -- Image pull secrets for private docker registry usages
imagePullSecrets: []

# -- String to override the default generated name
nameOverride: ""

# -- String to override the default generated fullname
fullnameOverride: ""

serviceAccount:
  # -- Specifies whether a ServiceAccount should be created
  create: true

  # -- Annotations to add to the service account. AWS EKS users can assign role arn from here.
  annotations:
    {}
    # eks.amazonaws.com/role-arn: ""

  # -- The name of the ServiceAccount to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# -- Annotations for the pod
podAnnotations: {}

# -- Security context for all pod
podSecurityContext:
  {}
  # fsGroup: 2000

# -- Security context for the mlflow container
securityContext:
  {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  # -- Specifies what type of Service should be created
  type: ClusterIP
  # -- Default Service port
  port: 5000

backendStore:
  # -- Specifies if you want to run database migration
  databaseMigration: false
  postgres:
    # -- Specifies if you want to use postgres backend storage
    enabled: false
    # -- Postgres host address. e.g. your RDS or Azure Postgres Service endpoint
    host: "" # required
    # -- Postgres service port
    port: 5432 # required
    # -- mlflow database name created before in the postgres instance
    database: "" # required
    # -- postgres database user name which can access to mlflow database
    user: "" # required
    # -- postgres database user password which can access to mlflow database
    password: "" # required

artifactRoot:
  azureBlob:
    # -- Specifies if you want to use Azure Blob Storage Mlflow Artifact Root
    enabled: false
    # -- Azure blob container name
    container: "" # required
    # -- Azure storage account name
    storageAccount: "" # required
    # -- Azure blobk container folder. If you want to use root level, please don't set anything.
    path: "" # optional
    # -- Azure Cloud Connection String for the container. Only onnectionString or accessKey required
    connectionString: "" # connectionString or accessKey required
    # -- Azure Cloud Storage Account Access Key for the container
    accessKey: "" # connectionString or accessKey required. Only onnectionString or accessKey required
  s3:
    # -- Specifies if you want to use AWS S3 Mlflow Artifact Root
    enabled: false
    # -- S3 bucket name
    bucket: "" # required
    # -- S3 bucket folder. If you want to use root level, please don't set anything.
    path: "" # optional
    # -- AWS IAM user AWS_ACCESS_KEY_ID which has attached policy for access to the S3 bucket
    awsAccessKeyId: "" # (awsAccessKeyId and awsSecretAccessKey) or roleArn serviceaccount annotation required
    # -- AWS IAM user AWS_SECRET_ACCESS_KEY which has attached policy for access to the S3 bucket
    awsSecretAccessKey: "" # (awsAccessKeyId and awsSecretAccessKey) or roleArn serviceaccount annotation required
  gcs:
    # -- Specifies if you want to use Google Cloud Storage Mlflow Artifact Root
    enabled: false
    # -- Google Cloud Storage bucket name
    bucket:
      "" # required
      # -- Google Cloud Storage bucket folder. If you want to use root level, please don't set anything.
    path: "" # optional

# -- A map of arguments and values to pass to the `mlflow server` command
# Keys must be camelcase. Helm will turn them to kebabcase style.
extraArgs: {}
# Number of gunicorn worker processes to handle requests (default: 4).
# workers: TEXT
# A prefix which will be prepended to the path of all static paths.
# staticPrefix: TEXT
# Additional command line options forwarded to gunicorn processes.
# gunicornOpts: TEXT
# Additional command line options for waitress-serve.
# waitressOpts: TEXT

# -- Extra environment variables
extraEnvVars:
  {}
  # MLFLOW_S3_IGNORE_TLS: true
  # MLFLOW_S3_UPLOAD_EXTRA_ARGS: '{"ServerSideEncryption": "aws:kms", "SSEKMSKeyId": "1234"}'
  # AWS_DEFAULT_REGION: my_region
  # MLFLOW_S3_ENDPOINT_URL: http://1.2.3.4:9000
  # AWS_CA_BUNDLE: /some/ca/bundle.pem
  # MLFLOW_GCS_DEFAULT_TIMEOUT - Sets the standard timeout for transfer operations in seconds (Default: 60). Use -1 for indefinite timeout.
  # MLFLOW_GCS_UPLOAD_CHUNK_SIZE - Sets the standard upload chunk size for bigger files in bytes (Default: 104857600 ≙ 100MiB), must be multiple of 256 KB.
  # MLFLOW_GCS_DOWNLOAD_CHUNK_SIZE - Sets the standard download chunk size for bigger files in bytes (Default: 104857600 ≙ 100MiB), must be multiple of 256 K

# -- Extra secrets for environment variables
extraSecretNamesForEnvFrom: []
# - my-mlflow-secrets

ingress:
  # -- Specifies if you want to create an ingress access
  enabled: false
  # -- New style ingress class name. Only possible if you use K8s 1.18.0 or later version
  className: ""
  # -- Additional ingress annotations
  annotations:
    {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          # -- Ingress path type
          pathType: ImplementationSpecific
  # -- Ingress tls configuration for https access
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

# -- Set the resources requests and limits
resources:
  {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

serviceMonitor:
  # -- When set true then use a ServiceMonitor to configure scraping
  enabled: false
  # -- Set the namespace the ServiceMonitor should be deployed
  namespace: monitoring
  # -- Set how frequently Prometheus should scrape
  interval: 30s
  # -- Set path to mlflow telemtery-path
  telemetryPath: /metrics
  # -- Set labels for the ServiceMonitor, use this to define your scrape label for Prometheus Operator
  labels:
    # -- default `kube prometheus stack` helm chart serviceMonitor selector label
    # Mostly it's your prometheus helm release name. Please find more information from here:
    # https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/troubleshooting.md#troubleshooting-servicemonitor-changes
    release: prometheus
  # -- Set timeout for scrape
  timeout: 10s
  # -- Set of labels to transfer on the Kubernetes Service onto the target.
  targetLabels: []

  # -- Set of rules to relabel your exist metric labels
  metricRelabelings:
    []
    # - sourceLabels: [prometheus_replica]
    #   regex: (.*)
    #   targetLabel: another_prometheus_replica
    #   action: replace
    # - regex: prometheus_replica
    #   action: labeldrop

# -- Set the node selector for the pod.
nodeSelector: {}

# -- Set the tolerations for the pod.
tolerations: []

# -- Set the affinity for the pod.
affinity: {}
