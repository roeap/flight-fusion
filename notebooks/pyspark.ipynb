{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "builder = SparkSession.builder.appName(\"flight-fusion-test\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from subprocess import STDOUT, check_output\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from pyarrow.fs import LocalFileSystem\n",
    "\n",
    "DATA_ROOT = \"_ff_data\"\n",
    "\n",
    "def file_relative_path(dunderfile, relative_path):\n",
    "    return os.path.join(os.path.dirname(dunderfile), relative_path)\n",
    "\n",
    "\n",
    "def workspace_root() -> Path:\n",
    "    output = check_output([\"cargo\", \"metadata\"], stderr=STDOUT).decode()  # nosec\n",
    "    key = 'workspace_root\":\"'\n",
    "    idx = output.find(key)\n",
    "    part = output[idx + len(key) :]\n",
    "    idx = part.find('\"')\n",
    "\n",
    "    return Path(part[:idx])\n",
    "\n",
    "data_path = workspace_root() / \"test\" / \"db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.date_range(\n",
    "    start=pd.to_datetime(\"2020-01-01 00:00:00\"),\n",
    "    end=pd.to_datetime(\"2020-01-04 00:00:00\"),\n",
    "    freq=\"3h\",\n",
    ")\n",
    "\n",
    "table = pa.Table.from_pydict(\n",
    "    {\n",
    "        \"timestamp\": ts,\n",
    "        \"date\":  pd.to_datetime(pd.Series(ts)).dt.date,\n",
    "        \"string\": np.random.choice([\"a\", \"b\", \"c\"], len(ts)),\n",
    "        \"double\": np.random.randn(len(ts)),\n",
    "        \"real\": np.random.randn(len(ts)),\n",
    "        \"float\": np.random.randn(len(ts)),\n",
    "    }\n",
    ")\n",
    "\n",
    "sdf = spark.createDataFrame(table.to_pandas()).repartition(1)\n",
    "\n",
    "sdf.write.format(\"delta\").save(str(data_path / \"delta\" / DATA_ROOT / \"simple\"), mode=\"overwrite\")\n",
    "sdf.write.format(\"delta\").partitionBy(\"date\").save(\n",
    "    str(data_path / \"delta\" / \"partitioned\" / DATA_ROOT / \"date\"), mode=\"overwrite\"\n",
    ")\n",
    "sdf.write.format(\"delta\").partitionBy(\"string\").save(\n",
    "    str(data_path / \"delta\" / \"partitioned\" / DATA_ROOT / \"string\"), mode=\"overwrite\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeltaTable.createIfNotExists(spark) \\\n",
    "  .tableName(\"people10m\") \\\n",
    "  .addColumn(\"id\", \"INT\") \\\n",
    "  .addColumn(\"firstName\", \"STRING\") \\\n",
    "  .addColumn(\"middleName\", \"STRING\") \\\n",
    "  .addColumn(\"lastName\", \"STRING\", comment = \"surname\") \\\n",
    "  .addColumn(\"gender\", \"STRING\") \\\n",
    "  .addColumn(\"birthDate\", \"TIMESTAMP\") \\\n",
    "  .addColumn(\"ssn\", \"STRING\") \\\n",
    "  .addColumn(\"salary\", \"INT\") \\\n",
    "  .location(\"tmp/people\") \\\n",
    "  .execute()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ef538eb184aaebad22e1576cbc02a4883cbaf547ee83f087cc18cec7532039b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('workspace-flight-fusion-jOezzoJ6-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
